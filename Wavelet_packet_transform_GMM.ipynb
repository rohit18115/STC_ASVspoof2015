{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    " \n",
    "# The GPU id to use, usually either \"0\" or \"1\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "import numpy as np\n",
    "import librosa as lb\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "from keras.utils import to_categorical,Sequence\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import History \n",
    "from keras.utils import plot_model,to_categorical\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy\n",
    "import scipy.io.wavfile\n",
    "from scipy.fftpack import dct\n",
    "# from iter_window import window \n",
    "import speechpy as sp\n",
    "# import statistics\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pywt\n",
    "import librosa as lb\n",
    "import speechpy as sp\n",
    "from keras.utils import plot_model,to_categorical\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for extracting Teaser Kaiser energy operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tkeo(a):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculates the TKEO of a given recording by using 2 samples.\n",
    "    See Li et al., 2007\n",
    "    Arguments:\n",
    "    a \t\t\t--- 1D numpy array.\n",
    "    Returns:\n",
    "    1D numpy array containing the tkeo per sample\n",
    "    \"\"\"\n",
    "    # Create two temporary arrays of equal length, shifted 1 sample to the right\n",
    "    # and left and squared:\n",
    "    i = a[1:-1]*a[1:-1]\n",
    "    j = a[2:]*a[:-2]\n",
    "    # Calculate the difference between the two temporary arrays:\n",
    "    aTkeo = i-j\n",
    "    return aTkeo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mel Wavelet Packet Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mwpc(signal,sample_rate):\n",
    "    pre_emphasis = 0.97\n",
    "    frame_size = 256\n",
    "    frame_stride = 128\n",
    "    nfilt = 20\n",
    "    NFFT = 511\n",
    "    emphasized_signal = numpy.append(signal[0], signal[1:] - pre_emphasis * signal[:-1])\n",
    "    frame_length, frame_step = frame_size, frame_stride  # Convert from seconds to samples\n",
    "    signal_length = len(emphasized_signal)\n",
    "    frame_length = int(round(frame_length))\n",
    "    frame_step = int(round(frame_step))\n",
    "    num_frames = int(numpy.ceil(float(numpy.abs(signal_length - frame_length)) / frame_step))  # Make sure that we have at least 1 frame\n",
    "#     print(num_frames)\n",
    "    pad_signal_length = num_frames * frame_step + frame_length\n",
    "    z = numpy.zeros((pad_signal_length - signal_length))\n",
    "    pad_signal = numpy.append(emphasized_signal, z) # Pad Signal to make sure that all frames have equal number of samples without truncating any samples from the original signal\n",
    "\n",
    "    indices = numpy.tile(numpy.arange(0, frame_length), (num_frames, 1)) + numpy.tile(numpy.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\n",
    "    frames = pad_signal[indices.astype(numpy.int32, copy=False)]\n",
    "    frames *= numpy.hamming(frame_length)\n",
    "    print(frames.shape)\n",
    "    audio_features = []\n",
    "    mel = lb.filters.mel(sr=sample_rate, n_fft=NFFT, n_mels=nfilt)\n",
    "    for f in frames:\n",
    "        tke = tkeo(f)\n",
    "        data_std = StandardScaler().fit_transform(tke.reshape(-1,1)).reshape(1,-1)[0]            \n",
    "        wptree = pywt.WaveletPacket(data=data_std, wavelet='db1', mode='symmetric')\n",
    "        level = wptree.maxlevel\n",
    "        levels = wptree.get_level(level, order = \"freq\")            \n",
    "        #Feature extraction for each node\n",
    "        frame_features = []        \n",
    "        for node in levels:\n",
    "            data_wp = node.data\n",
    "            # Features group\n",
    "            frame_features.extend(data_wp)\n",
    "#         print(len(frame_features))\n",
    "        mag_frames = numpy.absolute(frame_features)  # Magnitude of the FFT\n",
    "        pow_frames = numpy.abs((mag_frames) ** 2)\n",
    "        mel_scaled_features = mel.dot(pow_frames)\n",
    "        audio_features.append(mel_scaled_features)\n",
    "    \n",
    "    \n",
    "#     print(\"hello\")\n",
    "    log_energy = numpy.log10(audio_features)\n",
    "    log_energy = pd.DataFrame(log_energy)\n",
    "    pd.set_option('use_inf_as_null', True)\n",
    "    log_energy=log_energy.fillna(log_energy.mean())\n",
    "#     print(log_energy)\n",
    "    \n",
    "    pca = PCA(n_components=12)\n",
    "    mwpc = pca.fit_transform(log_energy)\n",
    "#     print(mwpc.shape)\n",
    "    \n",
    "#     low_freq_mel = 0\n",
    "#     high_freq_mel = (2595 * numpy.log10(1 + (sample_rate / 2) / 700))  # Convert Hz to Mel\n",
    "#     mel_points = numpy.linspace(low_freq_mel, high_freq_mel, nfilt + 2)  # Equally spaced in Mel scale\n",
    "#     hz_points = (700 * (10**(mel_points / 2595) - 1))  # Convert Mel to Hz\n",
    "#     bin = numpy.floor((NFFT + 1) * hz_points / sample_rate)\n",
    "    \n",
    "#     fbank = numpy.zeros((nfilt, int(numpy.floor(NFFT / 2 + 1))))\n",
    "#     for m in range(1, nfilt + 1):\n",
    "#         f_m_minus = int(bin[m - 1])   # left\n",
    "#         f_m = int(bin[m])             # center\n",
    "#         f_m_plus = int(bin[m + 1])    # right\n",
    "    \n",
    "#         for k in range(f_m_minus, f_m):\n",
    "#             fbank[m - 1, k] = (k - bin[m - 1]) / (bin[m] - bin[m - 1])\n",
    "#         for k in range(f_m, f_m_plus):\n",
    "#             fbank[m - 1, k] = (bin[m + 1] - k) / (bin[m + 1] - bin[m])\n",
    "#     filter_banks = numpy.dot(pow_frames, fbank.T)\n",
    "#     filter_banks = numpy.where(filter_banks == 0, numpy.finfo(float).eps, filter_banks)  # Numerical Stability\n",
    "#     filter_banks = 20 * numpy.log10(filter_banks)  # dB\n",
    "#     mfcc = dct(filter_banks, type=2, axis=1,n=num_ceps, norm='ortho') # Keep 2-13\n",
    "    return mwpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window( iterable, left, right, padding=0.0, step=1 ):\n",
    "   \n",
    "    from itertools import islice, repeat, chain\n",
    "    from collections import deque\n",
    "\n",
    "    n = left + right + 1\n",
    "\n",
    "    iterator = chain(iterable,repeat(padding,right)) \n",
    "    \n",
    "    elements = deque( repeat(padding,left), n )\n",
    "    elements.extend( islice( iterator, right - step + 1 ) )\n",
    "\n",
    "    while True: \n",
    "        for i in range(step):\n",
    "            elements.append( next(iterator) ) \n",
    "        yield tuple( elements ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class chunking_windowing(Sequence):\n",
    "    def __init__(self, data_train, train_labels, batch_size):\n",
    "        self.data_train = data_train\n",
    "        self.train_labels = train_labels\n",
    "        self.batch_size = batch_size\n",
    "        self.n = 0\n",
    "        self.max = self.__len__()\n",
    "        self.window_train = []\n",
    "    def __len__(self):\n",
    "        return np.ceil(len(self.data_train) / float(self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.data_train[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.train_labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "#         print(batch_x[1],idx)\n",
    "        self.window_train = []\n",
    "        for i in batch_x:\n",
    "            self.window_train.append(np.array(list(window(np.array(i),7,7))).ravel())\n",
    "#         print(len(self.window_train),len(batch_y))\n",
    "        return np.array(self.window_train), np.array(batch_y)\n",
    "    def __next__(self):\n",
    "        if self.n >= self.max:\n",
    "            self.n = 0\n",
    "        result = self.__getitem__(self.n)\n",
    "        self.n += 1\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.load(\"/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/spoof_deep_features/train_label.npy\")\n",
    "trimmed_audio = np.load(\"/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/original_datasets/npy_data_asvspoof/trimmed_audio.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.load(\"/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/spoof_deep_features/train_label.npy\")\n",
    "\n",
    "train_labels=list(train_labels)\n",
    "\n",
    "train_labels1 = list()\n",
    "for i in train_labels:\n",
    "    if i == b'human':\n",
    "        train_labels1.append(1)\n",
    "    else:\n",
    "        train_labels1.append(0)\n",
    "train_labels = to_categorical(train_labels1[:16000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to implement Wavelet packet transform\n",
    "## mwpc_train.py is used to extract the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590, 12)\n",
      "(590, 12)\n",
      "36\n",
      "21240\n"
     ]
    }
   ],
   "source": [
    "# # mwpc = []\n",
    "# mwpc_feat = mwpc(trimmed_audio[1],16000)\n",
    "# delta=np.array(lb.feature.delta(mwpc(trimmed_audio[1],16000)))\n",
    "# print(delta.shape)\n",
    "# delta2=np.array(lb.feature.delta(mwpc(trimmed_audio[1],16000), order=2))\n",
    "# print(delta2.shape)\n",
    "# value = np.concatenate([mwpc_feat,delta,delta2], axis=1)\n",
    "# print(len(value[1]))\n",
    "# mean_value = sp.processing.cmvnw(value).reshape(1,-1)\n",
    "# print(len(mean_value[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwpc_train = np.load(\"/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/spoof_deep_features/mwpc_train.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.load(\"/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/spoof_deep_features/train_label.npy\")\n",
    "\n",
    "train_labels=list(train_labels)\n",
    "\n",
    "train_labels1 = list()\n",
    "for i in train_labels:\n",
    "    if i == b'human':\n",
    "        train_labels1.append(1)\n",
    "    else:\n",
    "        train_labels1.append(0)\n",
    "train_labels = to_categorical(train_labels1[:16000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_batch_generator = chunking_windowing(mwpc_train,train_labels, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 512)               163123712 \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1000)              513000    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                64064     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 165,702,906\n",
      "Trainable params: 165,702,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "250/250 [==============================] - 259s 1s/step - loss: 0.6610 - acc: 0.7372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f77805bbed0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri1=[]\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Dense(512, activation='sigmoid', input_shape = (318600,)))\n",
    "model.add(Dense(1000, activation='sigmoid'))\n",
    "model.add(Dense(1000, activation='sigmoid'))\n",
    "model.add(Dense(1000, activation='sigmoid'))\n",
    "model.add(Dense(64, activation='linear'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "parallel_model = multi_gpu_model(model, gpus=2)\n",
    "model.summary()\n",
    "parallel_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "layeroutputs = []\n",
    "# for i in pad_window:\n",
    "# model.fit(data_train, to_categorical(train_labels), epochs = 1,batch_size = 64)#, callbacks = callbacks_list, validation_data=(x_validation,y_validation))\n",
    "parallel_model.fit_generator(generator=training_batch_generator,\n",
    "                                          epochs=1,\n",
    "                                          use_multiprocessing=True,\n",
    "                                          workers=16,\n",
    "                                          max_queue_size=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_5th_layer_output = K.function([model.layers[0].input],\n",
    "                                 [model.layers[4].output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n"
     ]
    }
   ],
   "source": [
    "output = np.empty((16000,64))\n",
    "for i in range(250):\n",
    "    tri,_=training_batch_generator.__getitem__(i)\n",
    "    output[i*64:(i+1)*64] = get_5th_layer_output([tri])[0]\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/original_datasets/npy_data_asvspoof/MWPC_BNF.npy\",output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset and Labels\n",
    "## 1 : Human and 0 : spoof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_embedding=np.load('/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/original_datasets/npy_data_asvspoof/MWPC_BNF.npy')\n",
    "train_labels = np.load(\"/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/spoof_deep_features/train_label.npy\")\n",
    "\n",
    "train_labels=list(train_labels)\n",
    "\n",
    "train_labels1 = list()\n",
    "for i in train_labels:\n",
    "    if i == b'human':\n",
    "        train_labels1.append(1)\n",
    "    else:\n",
    "        train_labels1.append(0)\n",
    "train_labels = train_labels1[0:16000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3674\n",
      "12326\n",
      "[ 5.96866831e-02  1.55276107e-02  2.33611777e-01  1.64725393e-01\n",
      " -2.99337320e-02 -3.38367015e-01  3.58855486e-01 -5.24151232e-03\n",
      "  4.33121212e-02  1.51735069e-02  4.49122906e-01 -2.10344806e-01\n",
      "  2.15686262e-02 -9.17317793e-02 -5.02841063e-02 -3.52597386e-02\n",
      " -4.31355089e-02  4.37280983e-01  1.01182656e-02  6.26722947e-02\n",
      " -1.91651937e-02  7.05243438e-05 -4.89485562e-02  4.80027765e-01\n",
      " -2.33716264e-01 -1.06510714e-01 -1.62068114e-01 -2.45212108e-01\n",
      " -4.74406928e-02  1.80612672e-02  2.61846125e-01  4.67075454e-03\n",
      " -3.15246210e-02  2.30454318e-02  4.06739525e-02  2.00639412e-01\n",
      "  3.69902812e-02 -5.86649776e-02  2.30197430e-01  2.84494311e-01\n",
      "  3.50865424e-02 -4.75288153e-01  2.00057849e-02 -1.90101713e-01\n",
      " -2.50988871e-01 -2.40288571e-01 -3.45558450e-02 -1.32315680e-02\n",
      "  5.55536091e-01 -9.81029421e-02  1.10662274e-01 -3.05693895e-01\n",
      "  1.69931099e-01 -1.00350991e-01  1.23799771e-01  4.10286903e-01\n",
      " -5.99236116e-02  5.91965914e-02  2.24794209e-01  3.68427671e-03\n",
      " -1.78716388e-02 -8.59286934e-02  6.76592961e-02 -3.78416717e-01]\n"
     ]
    }
   ],
   "source": [
    "j , k = 0,0\n",
    "# human_samples = np.empty((3674,17880)) # wrong array size as BNF is of size 3674,64\n",
    "human_samples = np.empty((3674,64))# corrected\n",
    "human_labels= []\n",
    "# spoof_samples = np.empty((12326,17880))\n",
    "spoof_samples = np.empty((12326,64))\n",
    "spoof_labels = []\n",
    "for count,i in enumerate(train_labels):\n",
    "    if i ==1:\n",
    "#         human_samples=np.append(human_samples,data_embedding[count])# Do not append insert the data at that position\n",
    "        human_samples[j]=data_embedding[count]\n",
    "        human_labels.append(train_labels[count])\n",
    "        j = j+1\n",
    "    elif i ==0:\n",
    "#         spoof_samples=np.append(spoof_samples,data_embedding[count])\n",
    "        spoof_samples[k] = data_embedding[count]\n",
    "        spoof_labels.append(train_labels[count])\n",
    "        k = k+1\n",
    "        \n",
    "print(len(human_labels))\n",
    "print(len(spoof_labels))\n",
    "print((human_samples[3673]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/original_datasets/npy_data_asvspoof/MWPC_human_samples.npy\",human_samples,allow_pickle=True)\n",
    "np.save(\"/media/hinton/F8E62A5EE62A1D7E/rohit/spoof/original_datasets/npy_data_asvspoof/MWPC_spoof_samples.npy\",spoof_samples,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit GMM for human samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GMM(n_components=512).fit(human_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit GMM for spoof samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_spoof = GMM(n_components=512).fit(spoof_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "llr_natural = gmm.score_samples(data_embedding)\n",
    "llr_spoof = gmm_spoof.score_samples(data_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "llr_score = llr_natural - llr_spoof     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = np.empty(16000)\n",
    "for i in range(len(llr_score)):\n",
    "    y_predicted[i] = int(llr_score[i]>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = roc_curve(train_labels, y_predicted)\n",
    "eer = brentq(lambda x : 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "thresh = interp1d(fpr, threshold)(eer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09488175145563989"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = roc_auc_score(train_labels,y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9468550397913479"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checking the shape after windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_audio = np.load(\"/home/rohita/rohit/spoof/npy_data_asvspoof/trimmed_audio.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rohita/rohit/spoof/work/lib/python2.7/site-packages/ipykernel_launcher.py:44: RuntimeWarning: divide by zero encountered in log10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 6.46205207e-18,  3.71677833e-15,  6.13587416e-15, ...,\n",
       "         2.04955142e-15, -1.95910947e-16, -7.26686921e-15],\n",
       "       [-6.15582680e-16,  8.03955227e-16, -6.54363227e-15, ...,\n",
       "        -2.07441260e-15,  3.51745137e-15,  6.28514622e-16],\n",
       "       [-6.18047241e-16, -1.25812833e-15, -7.76548501e-16, ...,\n",
       "         4.37364202e-16,  7.87144918e-16,  1.64664785e-16],\n",
       "       ...,\n",
       "       [ 8.56244561e-01,  2.09755426e-01,  2.53707627e-01, ...,\n",
       "        -1.15124080e-01, -2.07948314e-01,  3.23171259e-01],\n",
       "       [ 2.06090862e+00, -1.07001408e-01, -2.94432124e-01, ...,\n",
       "        -6.40454513e-02, -1.63598927e-01, -3.08527428e-01],\n",
       "       [ 2.06436088e+00, -3.20288420e-01, -1.53633905e-01, ...,\n",
       "        -1.25314770e-01, -1.80712388e-01, -1.88087846e-01]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mwpc(trimmed_audio[1],16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
